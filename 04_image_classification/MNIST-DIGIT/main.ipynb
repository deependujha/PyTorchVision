{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification on MNIST dataset ðŸ˜¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create transform for image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/vision/stable/auto_examples/transforms/plot_transforms_getting_started.html#i-just-want-to-do-image-classification\n",
    "\n",
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.PILToTensor(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get dataset & pass it into `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.MNIST(\n",
    "    \"./data\", train=True, transform=transforms, download=True\n",
    ")\n",
    "validation_set = torchvision.datasets.MNIST(\n",
    "    \"./data\", train=False, transform=transforms, download=True\n",
    ")\n",
    "\n",
    "# Class labels\n",
    "classes = (\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\")\n",
    "\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=4, shuffle=False\n",
    ")\n",
    "print(\"Training set has {} instances\".format(len(training_set)))\n",
    "print(\"Validation set has {} instances\".format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5  # un-normalize\n",
    "    np_img = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(np_img, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "\n",
    "\n",
    "data_iter = iter(training_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print(\"  \".join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{type(images)=}, {type(images[0])=}\")\n",
    "print(f\"{images.shape=}, {images[0].shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Let's start working on Classification Model ðŸ¦…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class MNISTDigitClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTDigitClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  # input= 1*28*28; output=6*24*24 (28-5+1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # input= 6*24*24; output=6*12*12 (24/2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  # input= 6*12*12; output=16*8*8 (12-5+1)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)  # after applying `self.pool`, 8/2 = 4. hence input (16*4*4)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MNISTDigitClassifier().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs.to(device=device))\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs.to(device=device), labels.to(device=device))\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000  # loss per batch\n",
    "            print(\"  batch {} loss: {}\".format(i + 1, last_loss))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_v_loss = 1_000_000.0\n",
    "\n",
    "print(f\"model will be using {device =}\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"EPOCH {}:\".format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "\n",
    "    running_v_loss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, v_data in enumerate(validation_loader):\n",
    "            v_inputs, v_labels = v_data\n",
    "            v_outputs = model(v_inputs.to(device=device))\n",
    "            v_loss = loss_fn(v_outputs.to(device=device), v_labels.to(device=device))\n",
    "            running_v_loss += v_loss\n",
    "\n",
    "    avg_v_loss = running_v_loss / (i + 1)\n",
    "    print(\"LOSS train {} valid {}\".format(avg_loss, avg_v_loss))\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model predictions ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_predictions():\n",
    "    # torch.manual_seed(42)\n",
    "\n",
    "    my_idx = torch.randint(high=len(validation_set), size=(5,))\n",
    "    print(f\"my random indexes are: {my_idx}\")\n",
    "\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i in my_idx:\n",
    "            curr_image, actual_label = validation_set[i]\n",
    "            prediction = model(transforms(curr_image))\n",
    "            predicted_label = prediction.argmax().item()\n",
    "            color = \"red\"\n",
    "            if actual_label==predicted_label:\n",
    "                color=\"green\"\n",
    "            # first transform the image and then let model predict\n",
    "            plt.imshow(curr_image.permute(1, 2, 0))\n",
    "            plt.title(f\"{actual_label=}; {predicted_label=}\", color=color)\n",
    "            plt.axis('off')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
